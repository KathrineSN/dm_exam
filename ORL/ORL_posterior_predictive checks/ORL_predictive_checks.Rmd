```{r}
install.packages("pacman")
pacman::p_load(R2jags, parallel, tidyverse)

set.seed(1982)

```

```{r}
MPD <- function(x) {
  density(x)$x[which(density(x)$y==max(density(x)$y))]
}
```


```{r}
# Loading the IGT data
data <- load("../../data/IGTdata.rdata")

source("../../data_preprocessing.R")

trials_95 <- data_preprocessing(choice_95, wi_95, lo_95, exclude_data = TRUE)
trials_100 <- data_preprocessing(choice_100, wi_100, lo_100, exclude_data = TRUE)
trials_150 <- data_preprocessing(choice_150, wi_150, lo_150, exclude_data = TRUE)

# make one big dataframe 
#df_final <- trials_100
length(unique(trials_100$subjID))

df_final <- trials_100
```

```{r}
subIDs <- unique(df_final$subjID)
nsubs <- length(subIDs)
#nsubs <- 10
ntrials_max <- 100

# all choices (x) and outcomes (X)
x_raw <- df_final$deck
X_raw <- df_final$gain + df_final$loss #note the sign!
```

```{r}
ntrials_all <- array(0,c(nsubs))
x_all <- array(0,c(nsubs,ntrials_max))
X_all <- array(0,c(nsubs,ntrials_max))

for (s in 1:nsubs) {
  
  #record n trials for subject s
  ntrials_all[s] <- length(x_raw[df_final$subjID==subIDs[s]])
  
  #pad trials with NA if n trials < maximum (i.e. 100)
  x_sub <- x_raw[df_final$subjID==subIDs[s]] 
  length(x_sub) <- ntrials_max
  
  X_sub <- X_raw[df_final$subjID==subIDs[s]] 
  length(X_sub) <- ntrials_max
  
  # assign arrays
  x_all[s,] <- x_sub
  X_all[s,] <- X_sub
  
}

# Scaling the payoffs (cuz the learning parameter becomes less relevant for very large payoffs/losses)
X_all <- X_all/100
```

```{r}
# fitting to one subject
x <- x_all[1,]
X <- X_all[1,]

ntrials <- ntrials_all[1]

# set up jags and run jags model on one subject
data <- list("x","X","ntrials") 
params<-c("a_rew","a_pun","K","theta","omega_f","omega_p","p")
temp_samples <- jags(data, inits=NULL, params,
                model.file ="../ORL.txt",
                n.chains=3, n.iter=5000, n.burnin=1000, n.thin=1)

# let's look at the posteriors for the parameters
par(mfrow=c(3,2))
plot(density(temp_samples$BUGSoutput$sims.list$a_rew))
plot(density(temp_samples$BUGSoutput$sims.list$a_pun))
plot(density(temp_samples$BUGSoutput$sims.list$theta))
plot(density(temp_samples$BUGSoutput$sims.list$K))
plot(density(temp_samples$BUGSoutput$sims.list$omega_f))
plot(density(temp_samples$BUGSoutput$sims.list$omega_p))

```



```{r}
# Running on all subs

p_post <- temp_samples$BUGSoutput$sims.list$p # probabilities as the outcome from softmax

#plot probability of each deck on trial 84
par(mfrow=c(2,2))
plot(density(p_post[,84,1]))
plot(density(p_post[,84,2]))
plot(density(p_post[,84,3]))
plot(density(p_post[,84,4]))

# which option will be chosen?
x[84]
# is this a good prediction?

# let's write a loop that loop and see how the model goes at predicting responses for all trials 
x_predict <- array(ntrials)

for (t in 1:ntrials) {
  
  p_predict <- c(
    MPD(p_post[,t,1]),
    MPD(p_post[,t,2]),
    MPD(p_post[,t,3]),
    MPD(p_post[,t,4])
  )
  
  x_predict[t] <- which.max(p_predict)
}
# how well did our model do?
sum(x_predict==x)

# let's see how the model goes for more than 1 subject. Let's run this on all subjects
pred_success <- array(nsubs)

start_time = Sys.time()

for (s in 1:nsubs) {
  
  x <- x_all[s, ]
  X <- X_all[s, ]
  
  ntrials <- ntrials_all[s]
  
  # set up jags and run jags model on one subject
  data <- list("x","X","ntrials") 
  params<-c("a_rew","a_pun","K","theta","omega_f","omega_p","p")
  temp_samples <- jags.parallel(data, inits=NULL, params,
                                model.file ="../ORL.txt",
                                n.chains=3, n.iter=5000, n.burnin=1000, n.thin=1, n.cluster=4)
  
  p_post <- temp_samples$BUGSoutput$sims.list$p
  
  x_predict <- array(ntrials)
  
  for (t in 1:ntrials) {
    p_predict <- c(
      MPD(p_post[,t,1]),
      MPD(p_post[,t,2]),
      MPD(p_post[,t,3]),
      MPD(p_post[,t,4])
    )
    
    x_predict[t] <- which.max(p_predict)
    
  }
  
  pred_success[s] <- sum(x_predict==x[1:ntrials]) # only comparing with trials for which we have choices
  print(s)
  
}

end_time = Sys.time()
end_time - start_time

pred_success_adjust <- pred_success/ntrials_all

avg_pred <- mean(pred_success_adjust)

# plotting code courtesy of Mia
pred_df <- data.frame(pred_success_adjust)
pred_df$sub <- 1:length(pred_success_adjust) # rownames(pred_df) # creating a subject index
pred_df$avg <- mean(pred_df$pred_success)
pred_df$std <- sd(pred_df$pred_success)
pred_df$chance <- .25
ggplot(pred_df, aes(sub, pred_success_adjust)) +
  geom_point() +
  geom_line(aes(y=chance), linetype="dashed", color = "black") +
  geom_ribbon(aes(xmin = -Inf, xmax = Inf, ymin = avg - std, ymax = avg + std), fill = "pink", alpha = 0.6) + 
  geom_line(aes(y=avg))

#setwd("/work/Exam project/dm_exam/ORL/ORL_posterior_predictive_checks/")
ggsave('poster_predictive_check_ORL.png')

```

```{r}
getwd()
```


```{r}
#setwd("/work/Exam project/dm_exam/ORL/ORL_posterior_predictive_checks/")
saveRDS(pred_df, file = "pred_df_ORL_posterior_predictive_checks.Rds")
```


```{r}
ggplot(pred_df, aes(sub, pred_success_adjust)) +
  geom_point() +
  geom_line(aes(y=chance), linetype="dashed", color = "black") +
  geom_ribbon(aes(xmin = -Inf, xmax = Inf, ymin = avg - std, ymax = avg + std), fill = "pink", alpha = 0.6) + 
  geom_line(aes(y=avg)) + labs(x = 'subject', y = 'predicted success percentage')
ggsave('poster_predictive_check_ORL.png')

```




